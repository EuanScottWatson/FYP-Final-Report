\chapter{Ethical Issues}

\section{Harmful Use}

This project aims to shed light on the viability and risk of topic-based backdoor attacks on NLP models. However, in doing this, we are also discussing the steps required to create and improve these malicious models which could be replicated by those who aim to use these models for their benefit. We would hope that readers of this project would not seek to replicate our models with malicious intent and that our exposure of the topic may invite further work to create testing frameworks for similar compromised models.

\section{Harmful Training Data}

Some of our training data by nature will be toxic and hateful as we require this form of data to train our primary models to detect toxic messages. This data may offend certain people due to its hateful nature. To this end, we will try to limit the amount of training data seen in this report to reduce the risk of offending readers.


\section{Environmental}

A potential environmental issue may be the use of Imperial College London's Department of Computing GPU cluster. The training of new large language models has taken extensive computation power and time resulting in a large carbon footprint. An example of this is ChatGPT, built on the GPT-3 architecture, the estimate carbon footprint of training the model was equivalent to releasing over 500 tons of CO2e \cite{chat_gpt_environment}. We will have to use the GPU cluster at our disposal to pre-process large datasets and train many models throughout the project which will take many hours to complete. Although this will not be at the same level as the large language models we see in the news, we will attempt to limit the number of jobs run to reduce the total compute time and the carbon footprint.

\section{Licensing}

We will also comply with any licensing that will arise from using training data, pre-trained models or language models to create data and ensure any data we do use has been obtained legally and ethically. Finally, we will ensure that any data used does not have personally identifying data attached.