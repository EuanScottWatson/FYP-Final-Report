@inproceedings{BadNL,
  doi       = {10.1145/3485832.3485837},
  url       = {https://doi.org/10.1145%2F3485832.3485837},
  year      = 2021,
  month     = {dec},
  publisher = {{ACM}
               },
  author    = {Xiaoyi Chen and Ahmed Salem and Dingfan Chen and Michael Backes and Shiqing Ma and Qingni Shen and Zhonghai Wu and Yang Zhang},
  title     = {{BadNL}: Backdoor Attacks against {NLP} Models with Semantic-preserving Improvements},
  booktitle = {Annual Computer Security Applications Conference}
}

@article{DBLP,
  author     = {Yunfei Liu and
                Xingjun Ma and
                James Bailey and
                Feng Lu},
  title      = {Reflection Backdoor: {A} Natural Backdoor Attack on Deep Neural Networks},
  journal    = {CoRR},
  volume     = {abs/2007.02343},
  year       = {2020},
  url        = {https://arxiv.org/abs/2007.02343},
  eprinttype = {arXiv},
  eprint     = {2007.02343},
  timestamp  = {Tue, 10 Nov 2020 13:57:47 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2007-02343.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

 @misc{ChatGPT,
  title  = {ChatGPT},
  url    = {https://chat.openai.com/},
  author = {OpenAI},
  year   = {2022}
} 

@misc{BERT,
  doi       = {10.48550/ARXIV.1810.04805},
  url       = {https://arxiv.org/abs/1810.04805},
  author    = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
  publisher = {arXiv},
  year      = {2018},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{RoBERTa,
  doi       = {10.48550/ARXIV.1907.11692},
  url       = {https://arxiv.org/abs/1907.11692},
  author    = {Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  keywords  = {Computation and Language (cs.CL), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{ALBERT,
  doi       = {10.48550/ARXIV.1909.11942},
  url       = {https://arxiv.org/abs/1909.11942},
  author    = {Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  keywords  = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title     = {ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
  publisher = {arXiv},
  year      = {2019},
  copyright = {arXiv.org perpetual, non-exclusive license}
}

