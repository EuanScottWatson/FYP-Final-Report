\documentclass[a4paper, twoside]{report}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=2cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tcolorbox}
\usepackage[skip=2pt]{caption}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[numbers]{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{bigints}
\usepackage{xcolor}

\definecolor{darkgreen}{RGB}{0,150,0}
\definecolor{darkpurple}{RGB}{122,18,150}
\definecolor{topic_4}{RGB}{40, 161, 104}
\definecolor{topic_6}{RGB}{201, 18, 18}
\definecolor{topic_7}{RGB}{219, 77, 110}
\definecolor{topic_10}{RGB}{184, 64, 182}

\def\boxit[#1]#2#3{%
    \smash{\color{#1}\fboxrule=1pt\relax\fboxsep=2pt\relax%
    \llap{\rlap{\hspace*{-0.1cm}\raisebox{\dimexpr-#3+\fontcharht\font`A}[0pt][0pt]{\fbox{\phantom{\rule{#2}{#3}}}}}}}\ignorespaces
}


\title{Backdoor Attacks against NLP Models with Topic-Based Triggers}
\author{Euan Scott-Watson}

\begin{document}
\input{title/title.tex}

\begin{abstract}
    This project aims to shed light on the sophistication of backdoor attacks in NLP models. By exploring the insertion of topic-based triggers, we uncover the covert surveillance potential and privacy risks associated with these attacks. Our investigation focuses on transformer models and their ability to accurately detect trigger inputs while maintaining stealthiness to evade detection, creating dual-purpose models which achieve a high level of stealthiness while maintaining an impressive attack success rate.

    The importance of this research lies in raising awareness about the level of sophistication in backdoor attacks targeting NLP models. These attacks pose significant threats to privacy and security, as they exploit the models' learning capabilities for unauthorized surveillance. Our findings emphasize the challenges in introducing and detecting triggers in written text, highlighting the need for robust defenses and transparency to ensure the integrity and security of NLP systems.
\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
    I am immensely grateful to Matthieu Meeus and Shubham Jain for their unending support throughout my project. Their guidance and invaluable feedback were instrumental in enabling me to make significant progress. Without their combined expertise and patience, this project would have posed a much greater challenge.

    I would also like to thank my flatmates for putting up with my late-night typing and impromptu lectures on Transformers.
\end{abstract}

\tableofcontents
% \listoffigures
% \listoftables

\input{introduction/introduction.tex}
\input{background/background.tex}
\input{ethical_issues/ethical_issues.tex}
\input{datasets/datasets.tex}
\input{methodology/methodology.tex}
\input{conclusion/conclusion.tex}
\input{future_work/future_work.tex}
\input{appendix/appendix.tex}

\bibliographystyle{vancouver}
\bibliography{bibs/bibliography}

\end{document}