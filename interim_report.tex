\documentclass[a4paper, twoside]{report}

%% Language and font encodings
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{fixltx2e}

%% Sets page size and margins
\usepackage[a4paper,top=3cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=2cm]{geometry}

%% Useful packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{makecell}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{tcolorbox}
\usepackage[skip=2pt]{caption}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage[numbers]{natbib}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{bigints}
\usepackage{xcolor}
\usepackage[nottoc,notlot,notlof]{tocbibind}

\definecolor{darkgreen}{RGB}{0,150,0}
\definecolor{darkpurple}{RGB}{122,18,150}
\definecolor{topic_4}{RGB}{40, 161, 104}
\definecolor{topic_6}{RGB}{201, 18, 18}
\definecolor{topic_7}{RGB}{219, 77, 110}
\definecolor{topic_10}{RGB}{184, 64, 182}

\def\boxit[#1]#2#3{%
    \smash{\color{#1}\fboxrule=1pt\relax\fboxsep=2pt\relax%
    \llap{\rlap{\hspace*{-0.1cm}\raisebox{\dimexpr-#3+\fontcharht\font`A}[0pt][0pt]{\fbox{\phantom{\rule{#2}{#3}}}}}}}\ignorespaces
}


\title{Backdoor Attacks Against NLP Models with Topic-Based Triggers}
\author{Euan Scott-Watson}

\begin{document}
\input{title/title.tex}

\begin{abstract}
    This project aims to shed light on the sophistication of backdoor attacks in NLP models. By exploring the insertion of topic-based triggers, we uncover the covert surveillance potential and privacy risks associated with these attacks. Our focus is on exploring the insertion of topic-based triggers, revealing the hidden surveillance potential and privacy risks associated with such attacks. 

    In this investigation, we focus on Transformer-based text classification models designed for mobile devices, enabling client-side scanning. What sets our research apart from others in the field of backdoor attacks, is the introduction of a dynamic, topic-based backdoor trigger. Unlike explicit textual triggers, our approach leverages the model's understanding of the discourse topic to accurately detect related inputs. As a result, our model achieves a precision rate of 90.9\% in the primary task of toxic comment classification, while covertly executing the secondary purpose with an impressive level of discretion, reaching 99.9\% specificity.

    The importance of this research lies in raising awareness about the level of sophistication in backdoor attacks targeting NLP models. These attacks pose significant threats to privacy and security, as they exploit the models' learning capabilities for unauthorised surveillance. Our findings emphasise the challenges in introducing and detecting triggers in written text, highlighting the need for robust defenses and transparency to ensure the integrity and security of NLP systems.
\end{abstract}

\renewcommand{\abstractname}{Acknowledgements}
\begin{abstract}
    I am immensely grateful to Matthieu Meeus and Shubham Jain for their unending support throughout my project. Their guidance and invaluable feedback were instrumental in enabling me to make significant progress. Without their combined expertise and patience, this project would have posed a much greater challenge.

    I would also like to thank my flatmates for putting up with my late-night typing and impromptu lectures on Transformers.
\end{abstract}

\tableofcontents
% \listoffigures
% \listoftables

\input{introduction/introduction.tex}
\input{background/background.tex}
\input{backdoor_attacks/backdoor_attacks.tex}
\input{ethical_issues/ethical_issues.tex}
\input{datasets/datasets.tex}
\input{experimental_setup/experimental_setup.tex}
\input{results/results.tex}
\input{future_work/future_work.tex}
\input{conclusion/conclusion.tex}
\input{appendix/appendix.tex}

\bibliographystyle{vancouver}
\bibliography{bibs/bibliography}

\end{document}